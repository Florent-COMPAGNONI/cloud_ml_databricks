{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import KNNImputer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"data/train.csv\").drop(columns=['Unnamed: 0', 'N°DPE'])\n",
    "test_data = pd.read_csv(\"data/test.csv\").drop(columns=['Unnamed: 0', 'N°DPE'])\n",
    "# val_data = pd.read_csv(\"data/val.csv\").drop(columns=['N°DPE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split():\n",
    "    X_train  = train_data.drop(columns=['Etiquette_DPE'])\n",
    "    y_train  = train_data['Etiquette_DPE']\n",
    "\n",
    "    X_test = test_data.drop(columns=[\"Etiquette_DPE\"])\n",
    "    y_test = test_data[\"Etiquette_DPE\"]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_categorical():\n",
    "    X_train, y_train, X_test, y_test = train_test_split()\n",
    "\n",
    "    for dataset in [X_train, X_test]:\n",
    "        dataset[dataset.select_dtypes(['object']).columns] = dataset.select_dtypes(['object']).apply(lambda x: x.astype('category').cat.codes)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nan():\n",
    "    X_train, y_train, X_test, y_test = to_categorical()\n",
    "\n",
    "    for col in X_train.select_dtypes(include=['float64', 'int64']).columns:\n",
    "        median = X_train[col].median()\n",
    "        X_train[col].fillna(median, inplace=True)\n",
    "        X_test[col].fillna(median, inplace=True)\n",
    "    \n",
    "    for col in X_train.select_dtypes(include=['object', 'category']).columns:\n",
    "        mode = X_train[col].mode()[0]\n",
    "        X_train[col].fillna(mode, inplace=True)\n",
    "        X_test[col].fillna(mode, inplace=True)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_imputer(n_neighbors: int = 2):\n",
    "    X_train, y_train, X_test, y_test = to_categorical()\n",
    "\n",
    "    imputer = KNNImputer(n_neighbors=n_neighbors)\n",
    "    X_train = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)\n",
    "    X_test = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipeline_preprocessing(onehot: bool = True):\n",
    "\n",
    "    numerical_cols = train_data.select_dtypes(include=['float64', 'int64']).columns\n",
    "    categorical_cols = train_data.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "    transformers = [\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder() if onehot else OrdinalEncoder(), categorical_cols)\n",
    "    ]\n",
    "    preprocessor = ColumnTransformer(transformers)\n",
    "\n",
    "    steps = [\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        ('imputer', KNNImputer(n_neighbors=2)),\n",
    "    ]\n",
    "\n",
    "    return steps\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HistGradientBoostingClassifier\n",
    "no pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9800\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = to_categorical()\n",
    "\n",
    "gradient_boosting_clf = HistGradientBoostingClassifier()\n",
    "gradient_boosting_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_val = gradient_boosting_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred_val)\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with fill nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9794\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = fill_nan()\n",
    "\n",
    "gradient_boosting_clf = HistGradientBoostingClassifier()\n",
    "gradient_boosting_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_val = gradient_boosting_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred_val)\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9868\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = fill_nan()\n",
    "\n",
    "gradient_boosting_clf = HistGradientBoostingClassifier(learning_rate=0.01, max_iter=1000)\n",
    "gradient_boosting_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_val = gradient_boosting_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred_val)\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\florent\\Documents\\ESGI\\5-IABD\\Cloud avancé pour le ml et le big data\\cloud_ml\\test.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/florent/Documents/ESGI/5-IABD/Cloud%20avanc%C3%A9%20pour%20le%20ml%20et%20le%20big%20data/cloud_ml/test.ipynb#Y113sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m X_train, y_train, X_test, y_test \u001b[39m=\u001b[39m knn_imputer()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/florent/Documents/ESGI/5-IABD/Cloud%20avanc%C3%A9%20pour%20le%20ml%20et%20le%20big%20data/cloud_ml/test.ipynb#Y113sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m gradient_boosting_clf \u001b[39m=\u001b[39m HistGradientBoostingClassifier()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/florent/Documents/ESGI/5-IABD/Cloud%20avanc%C3%A9%20pour%20le%20ml%20et%20le%20big%20data/cloud_ml/test.ipynb#Y113sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m gradient_boosting_clf\u001b[39m.\u001b[39mfit(X_train, y_train)\n",
      "\u001b[1;32mc:\\Users\\florent\\Documents\\ESGI\\5-IABD\\Cloud avancé pour le ml et le big data\\cloud_ml\\test.ipynb Cell 18\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/florent/Documents/ESGI/5-IABD/Cloud%20avanc%C3%A9%20pour%20le%20ml%20et%20le%20big%20data/cloud_ml/test.ipynb#Y113sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m X_train, y_train, X_test, y_test \u001b[39m=\u001b[39m to_categorical()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/florent/Documents/ESGI/5-IABD/Cloud%20avanc%C3%A9%20pour%20le%20ml%20et%20le%20big%20data/cloud_ml/test.ipynb#Y113sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m imputer \u001b[39m=\u001b[39m KNNImputer(n_neighbors\u001b[39m=\u001b[39mn_neighbors)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/florent/Documents/ESGI/5-IABD/Cloud%20avanc%C3%A9%20pour%20le%20ml%20et%20le%20big%20data/cloud_ml/test.ipynb#Y113sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m X_train \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(imputer\u001b[39m.\u001b[39;49mfit_transform(X_train), columns\u001b[39m=\u001b[39mX_train\u001b[39m.\u001b[39mcolumns)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/florent/Documents/ESGI/5-IABD/Cloud%20avanc%C3%A9%20pour%20le%20ml%20et%20le%20big%20data/cloud_ml/test.ipynb#Y113sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m X_test \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(imputer\u001b[39m.\u001b[39mtransform(X_test), columns\u001b[39m=\u001b[39mX_test\u001b[39m.\u001b[39mcolumns)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/florent/Documents/ESGI/5-IABD/Cloud%20avanc%C3%A9%20pour%20le%20ml%20et%20le%20big%20data/cloud_ml/test.ipynb#Y113sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mreturn\u001b[39;00m X_train, y_train, X_test, y_test\n",
      "File \u001b[1;32mc:\\Users\\florent\\_python_environments\\cloud_venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 157\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    158\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    159\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    160\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[0;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    162\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    163\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\florent\\_python_environments\\cloud_venv\\lib\\site-packages\\sklearn\\base.py:916\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    914\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    915\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 916\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39;49mtransform(X)\n\u001b[0;32m    917\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    918\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    919\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\florent\\_python_environments\\cloud_venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 157\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    158\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    159\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    160\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[0;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    162\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    163\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\florent\\_python_environments\\cloud_venv\\lib\\site-packages\\sklearn\\impute\\_knn.py:365\u001b[0m, in \u001b[0;36mKNNImputer.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[39m# process in fixed-memory chunks\u001b[39;00m\n\u001b[0;32m    357\u001b[0m gen \u001b[39m=\u001b[39m pairwise_distances_chunked(\n\u001b[0;32m    358\u001b[0m     X[row_missing_idx, :],\n\u001b[0;32m    359\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_X,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    363\u001b[0m     reduce_func\u001b[39m=\u001b[39mprocess_chunk,\n\u001b[0;32m    364\u001b[0m )\n\u001b[1;32m--> 365\u001b[0m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m gen:\n\u001b[0;32m    366\u001b[0m     \u001b[39m# process_chunk modifies X in place. No return value.\u001b[39;00m\n\u001b[0;32m    367\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m    369\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkeep_empty_features:\n",
      "File \u001b[1;32mc:\\Users\\florent\\_python_environments\\cloud_venv\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:2027\u001b[0m, in \u001b[0;36mpairwise_distances_chunked\u001b[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[0;32m   2025\u001b[0m \u001b[39mif\u001b[39;00m reduce_func \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2026\u001b[0m     chunk_size \u001b[39m=\u001b[39m D_chunk\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m-> 2027\u001b[0m     D_chunk \u001b[39m=\u001b[39m reduce_func(D_chunk, sl\u001b[39m.\u001b[39;49mstart)\n\u001b[0;32m   2028\u001b[0m     _check_chunk_size(D_chunk, chunk_size)\n\u001b[0;32m   2029\u001b[0m \u001b[39myield\u001b[39;00m D_chunk\n",
      "File \u001b[1;32mc:\\Users\\florent\\_python_environments\\cloud_venv\\lib\\site-packages\\sklearn\\impute\\_knn.py:328\u001b[0m, in \u001b[0;36mKNNImputer.transform.<locals>.process_chunk\u001b[1;34m(dist_chunk, start)\u001b[0m\n\u001b[0;32m    323\u001b[0m dist_subset \u001b[39m=\u001b[39m dist_chunk[dist_idx_map[receivers_idx] \u001b[39m-\u001b[39m start][\n\u001b[0;32m    324\u001b[0m     :, potential_donors_idx\n\u001b[0;32m    325\u001b[0m ]\n\u001b[0;32m    327\u001b[0m \u001b[39m# receivers with all nan distances impute with mean\u001b[39;00m\n\u001b[1;32m--> 328\u001b[0m all_nan_dist_mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49misnan(dist_subset)\u001b[39m.\u001b[39mall(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m    329\u001b[0m all_nan_receivers_idx \u001b[39m=\u001b[39m receivers_idx[all_nan_dist_mask]\n\u001b[0;32m    331\u001b[0m \u001b[39mif\u001b[39;00m all_nan_receivers_idx\u001b[39m.\u001b[39msize:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = knn_imputer()\n",
    "\n",
    "gradient_boosting_clf = HistGradientBoostingClassifier()\n",
    "gradient_boosting_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_val = gradient_boosting_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred_val)\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = build_pipeline_preprocessing()\n",
    "steps.append(('classifier', HistGradientBoostingClassifier()))\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred_val = pipeline.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_val)\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RadomForest\n",
    "with fill nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9921\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = fill_nan()\n",
    "\n",
    "clf_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_val = clf_rf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred_val)\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = knn_imputer()\n",
    "\n",
    "clf_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_val = clf_rf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred_val)\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom transformer for numerical columns\n",
    "class NumericalImputer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.medians = X.median()\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_copy = X.copy()\n",
    "        for col in X_copy.columns:\n",
    "            X_copy[col].fillna(self.medians[col], inplace=True)\n",
    "        return X_copy\n",
    "\n",
    "# Custom transformer for categorical columns\n",
    "class CategoricalImputer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.modes = X.mode().iloc[0]\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_copy = X.copy()\n",
    "        for col in X_copy.columns:\n",
    "            X_copy[col].fillna(self.modes[col], inplace=True)\n",
    "        return X_copy\n",
    "\n",
    "# SimpleImputer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloud_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
